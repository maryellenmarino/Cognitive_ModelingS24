{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 9: AI-Assisted Programming\n",
    "Use ChatGPT or any other large language model (LLM) to generate a function called multivariate normal density(x, mu, Sigma) which returns the density of a D-dimensional vector x given a D-dimensional mean (location) vector\n",
    "mu and a D×D-dimensional covariance matrix Cov. Compare the outputs of your\n",
    "function with those obtained using SciPy’s scipy.stats.multivariate_normal\n",
    "for a few parameterizations including a spherical Gaussian (zero covariance, shared variance across dimensions), a diagonal Gaussian (zero covariance, different variance for each dimension), and a full-covariance Gaussian (non-zero covariance, different variance for each dimension). Describe briefly how the LLM performed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important imports\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI-Generated Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_normal_density(x, mu, Sigma):\n",
    "    \"\"\"\n",
    "    Calculate the density of a D-dimensional vector x given a D-dimensional mean (location) vector mu\n",
    "    and a covariance matrix Sigma.\n",
    "\n",
    "    Parameters:\n",
    "    - x: D-dimensional numpy array representing the vector whose density needs to be calculated.\n",
    "    - mu: D-dimensional numpy array representing the mean vector.\n",
    "    - Sigma: DxD numpy array representing the covariance matrix.\n",
    "\n",
    "    Returns:\n",
    "    - density: Density of the vector x.\n",
    "    \"\"\"\n",
    "    D = len(mu)\n",
    "    det = np.linalg.det(Sigma)\n",
    "    inv_Sigma = np.linalg.inv(Sigma)\n",
    "    norm_const = 1.0 / np.sqrt((2 * np.pi) ** D * det)\n",
    "    x_mu = x - mu\n",
    "    exponent = -0.5 * np.dot(np.dot(x_mu, inv_Sigma), x_mu.T)\n",
    "    density = norm_const * np.exp(exponent)\n",
    "    return density\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spherical Gaussian\n",
    "For the spherical Gaussian, we use a covariance matrix with zero covariance and the same variance for each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spherical Gaussian:\n",
      "AI-Generated function density: 0.020130695075512038\n",
      "SciPy density: 0.020130695075512045\n",
      "Difference: 6.938893903907228e-18\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "D = 3  # Number of dimensions\n",
    "variance = 2.0\n",
    "mu = np.random.rand(D)\n",
    "Sigma = np.eye(D) * variance  # Spherical covariance matrix\n",
    "x = np.random.rand(D)\n",
    "\n",
    "# Calculate densities\n",
    "ai_density = multivariate_normal_density(x, mu, Sigma)\n",
    "scipy_density = stats.multivariate_normal(mean=mu, cov=Sigma).pdf(x)\n",
    "\n",
    "density_difference = np.abs(ai_density - scipy_density)\n",
    "\n",
    "# Compare\n",
    "print(f\"Spherical Gaussian:\\nAI-Generated function density: {ai_density}\\nSciPy density: {scipy_density}\\nDifference: {density_difference}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagonal Gaussian\n",
    "For the diagonal Gaussian, we use a covariance matrix with zero covariance and different variances for each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagonal Gaussian:\n",
      "AI-Generated function density: 0.025491653953254187\n",
      "SciPy density: 0.025491653953254197\n",
      "Difference: 1.0408340855860843e-17\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "variances = np.random.rand(D) * 3  # Different variances\n",
    "Sigma = np.diag(variances)  # Diagonal covariance matrix\n",
    "x = np.random.rand(D)\n",
    "\n",
    "# Calculate densities\n",
    "ai_density = multivariate_normal_density(x, mu, Sigma)\n",
    "scipy_density = stats.multivariate_normal(mean=mu, cov=Sigma).pdf(x)\n",
    "\n",
    "density_difference = np.abs(ai_density - scipy_density)\n",
    "\n",
    "# Compare\n",
    "print(f\"Diagonal Gaussian:\\nAI-Generated function density: {ai_density}\\nSciPy density: {scipy_density}\\nDifference: {density_difference}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full-Covariance Gaussian\n",
    "For the full-covariance Gaussian, we use a covariance matrix with non-zero covariance and different variances for each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full-Covariance Gaussian:\n",
      "AI-Generated function density: 2.153809648055261\n",
      "SciPy density: 2.1538096480551\n",
      "Difference: 1.6076029396572267e-13\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "Sigma = np.random.rand(D, D)\n",
    "Sigma = np.matmul(Sigma, Sigma.T) # Ensure the covariance matrix is positive semi-definite\n",
    "x = np.random.rand(D)\n",
    "\n",
    "# Calculate densities\n",
    "ai_density = multivariate_normal_density(x, mu, Sigma)\n",
    "scipy_density = stats.multivariate_normal(mean=mu, cov=Sigma).pdf(x)\n",
    "\n",
    "density_difference = np.abs(ai_density - scipy_density)\n",
    "\n",
    "# Compare\n",
    "print(f\"Full-Covariance Gaussian:\\nAI-Generated function density: {ai_density}\\nSciPy density: {scipy_density}\\nDifference: {density_difference}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Performance Discussion\n",
    "#### Describe briefly how the LLM performed.\n",
    "The AI-generated function's performance in calculating the density of a multivariate normal distribution is notably precise, closely mirroring the results from the well-established SciPy library, although not exactly matching them. The exceedingly small differences in the output, such as `6.94 x 10^-18` for the Spherical Gaussian and slightly larger but still minimal discrepancies for the Diagonal and Full-Covariance Gaussians, highlight a level of accuracy that surpasses typical expectations for AI-generated algorithms. These minor variances, while potentially attributable to the nuances of floating-point computations, importantly display that the AI's output is not an exact replica of SciPy's function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognitive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
